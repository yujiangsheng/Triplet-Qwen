"""
Agentæ¼”åŒ–ç³»ç»Ÿ - è‡ªåŠ¨ä¼˜åŒ–Agent Aå’ŒBçš„æ€§èƒ½

æ ¸å¿ƒæ¦‚å¿µ:
1. æ•°æ®é©±åŠ¨çš„æ¼”åŒ– - ä½¿ç”¨ä»ç½‘ç»œçˆ¬å–çš„æ•°æ®
2. æŒç»­åé¦ˆå¾ªç¯ - Aâ†’Bâ†’åé¦ˆâ†’æ”¹è¿›
3. æ€§èƒ½è¿½è¸ª - è®°å½•æ¯ä¸ªç‰ˆæœ¬çš„æ€§èƒ½
4. è‡ªåŠ¨ä¼˜åŒ– - æ ¹æ®æ€§èƒ½è°ƒæ•´å‚æ•°å’Œè§„åˆ™

æ¼”åŒ–æµç¨‹:
  åˆå§‹åŒ– â†’ çˆ¬å–æ•°æ® â†’ éªŒè¯ â†’ è¯„ä¼° â†’ ä¼˜åŒ– â†’ è¿­ä»£ â†’ æ”¶æ•›
"""

import json
import time
from typing import Dict, List, Any, Tuple, Optional
from dataclasses import dataclass, asdict
from datetime import datetime
from collections import defaultdict
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class EvolutionMetrics:
    """æ¼”åŒ–æŒ‡æ ‡"""
    version: int                    # æ¼”åŒ–ç‰ˆæœ¬
    timestamp: float                # æ—¶é—´æˆ³
    accuracy: float                 # æ•´ä½“å‡†ç¡®ç‡
    extraction_accuracy: float      # æŠ½å–å‡†ç¡®ç‡ (Agent A)
    validation_accuracy: float      # éªŒè¯å‡†ç¡®ç‡ (Agent B)
    argument_integrity: float       # è®ºå…ƒå®Œæ•´æ€§ (0-1)
    semantic_completeness: float    # è¯­ä¹‰å®Œæ•´æ€§ (0-1)
    avg_revision_rounds: float      # å¹³å‡ä¿®è®¢è½®æ•°
    converged: bool = False         # æ˜¯å¦å·²æ”¶æ•›
    
    def improvement_over_previous(self, previous: 'EvolutionMetrics') -> float:
        """ç›¸å¯¹äºä¸Šä¸€ç‰ˆæœ¬çš„æ”¹è¿›"""
        if not previous:
            return 0.0
        return self.accuracy - previous.accuracy


class EvolutionSystem:
    """
    Agentæ¼”åŒ–ç³»ç»Ÿ
    
    èŒè´£:
    1. ç®¡ç†æ¼”åŒ–è¿‡ç¨‹
    2. è¯„ä¼°æ€§èƒ½
    3. è§¦å‘ä¼˜åŒ–
    4. è¿½è¸ªå†å²
    """
    
    def __init__(self, agent_a, agent_b, data_crawler, 
                 max_iterations: int = 20,
                 convergence_threshold: float = 0.01,
                 target_accuracy: float = 0.90):
        """
        åˆå§‹åŒ–æ¼”åŒ–ç³»ç»Ÿ
        
        Args:
            agent_a: Agent Aå®ä¾‹
            agent_b: Agent Bå®ä¾‹
            data_crawler: DataCrawlerå®ä¾‹
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
            convergence_threshold: æ”¶æ•›é˜ˆå€¼ (æ”¹è¿›%æ•°)
            target_accuracy: ç›®æ ‡å‡†ç¡®ç‡
        """
        self.agent_a = agent_a
        self.agent_b = agent_b
        self.data_crawler = data_crawler
        
        self.max_iterations = max_iterations
        self.convergence_threshold = convergence_threshold
        self.target_accuracy = target_accuracy
        
        self.evolution_history: List[EvolutionMetrics] = []
        self.current_version = 0
        self.should_stop = False
    
    def start_evolution(self, initial_dataset_size: int = 200) -> Dict[str, Any]:
        """
        å¼€å§‹è‡ªåŠ¨æ¼”åŒ–è¿‡ç¨‹
        
        Args:
            initial_dataset_size: åˆå§‹æ•°æ®é›†å¤§å°
            
        Returns:
            æ¼”åŒ–ç»“æœæ€»ç»“
        """
        logger.info("="*70)
        logger.info("å¼€å§‹Agentè‡ªåŠ¨æ¼”åŒ–å¾ªç¯")
        logger.info("="*70)
        
        # ç¬¬1æ­¥: çˆ¬å–åˆå§‹æ•°æ®é›†
        logger.info(f"\n[ç¬¬1æ­¥] çˆ¬å–åˆå§‹æ•°æ®é›† (å¤§å°: {initial_dataset_size})")
        initial_dataset = self.data_crawler.crawl_all_sources(
            per_source=initial_dataset_size // 4
        )
        initial_dataset = self.data_crawler.filter_by_quality(
            initial_dataset, min_quality=0.5
        )
        logger.info(f"âœ“ çˆ¬å–å®Œæˆ: {len(initial_dataset)} ä¸ªå¥å­")
        
        # ç¬¬2æ­¥: å¼€å§‹è¿­ä»£ä¼˜åŒ–
        for iteration in range(self.max_iterations):
            self.current_version = iteration + 1
            logger.info(f"\n{'='*70}")
            logger.info(f"æ¼”åŒ–è¿­ä»£ {self.current_version}/{self.max_iterations}")
            logger.info(f"{'='*70}")
            
            # é˜¶æ®µ1: éªŒè¯
            logger.info(f"\n[é˜¶æ®µ1] éªŒè¯...")
            metrics = self._validate_on_dataset(initial_dataset)
            
            # è®°å½•æŒ‡æ ‡
            self.evolution_history.append(metrics)
            self._log_metrics(metrics)
            
            # æ£€æŸ¥æ”¶æ•›
            if self._check_convergence(metrics):
                logger.info(f"\nâœ“ ç³»ç»Ÿå·²æ”¶æ•›ï¼Œåœæ­¢æ¼”åŒ–")
                break
            
            # æ£€æŸ¥ç›®æ ‡
            if metrics.accuracy >= self.target_accuracy:
                logger.info(f"\nâœ“ è¾¾åˆ°ç›®æ ‡å‡†ç¡®ç‡ {self.target_accuracy:.2%}")
                break
            
            # é˜¶æ®µ2: ä¼˜åŒ–
            logger.info(f"\n[é˜¶æ®µ2] ä¼˜åŒ–...")
            self._optimize_agents(metrics, initial_dataset)
            
            # é˜¶æ®µ3: æ•°æ®æ›´æ–°
            if iteration % 3 == 2:  # æ¯3æ¬¡è¿­ä»£æ›´æ–°ä¸€æ¬¡æ•°æ®
                logger.info(f"\n[é˜¶æ®µ3] æ›´æ–°æ•°æ®é›†...")
                new_data = self.data_crawler.crawl_all_sources(
                    per_source=(initial_dataset_size // 4) // 2
                )
                initial_dataset.extend(new_data)
                logger.info(f"âœ“ æ•°æ®é›†å·²æ›´æ–°: {len(initial_dataset)} ä¸ªå¥å­")
        
        # è¿”å›ç»“æœ
        return self._generate_evolution_report()
    
    def _validate_on_dataset(self, dataset) -> EvolutionMetrics:
        """
        åœ¨æ•°æ®é›†ä¸ŠéªŒè¯agents
        
        Args:
            dataset: å¥å­åˆ—è¡¨
            
        Returns:
            æ¼”åŒ–æŒ‡æ ‡
        """
        results = {
            'extraction_count': 0,
            'extraction_correct': 0,
            'validation_count': 0,
            'validation_correct': 0,
            'integrity_scores': [],
            'completeness_scores': [],
            'revision_rounds': []
        }
        
        for sentence in dataset[:100]:  # é™åˆ¶éªŒè¯è§„æ¨¡ä»¥åŠ å¿«æ¼”åŒ–
            try:
                # Agent A: æŠ½å–
                triplet = self.agent_a.extract_triplets(sentence.text)
                results['extraction_count'] += 1
                
                # ç®€å•å¯å‘å¼æ£€æŸ¥
                if self._is_reasonable_triplet(triplet, sentence.text):
                    results['extraction_correct'] += 1
                
                # Agent B: éªŒè¯
                validation_result = self.agent_b.validate_triplet(
                    sentence.text, triplet
                )
                results['validation_count'] += 1
                
                if validation_result.get('is_valid'):
                    results['validation_correct'] += 1
                
                # è®°å½•è´¨é‡æŒ‡æ ‡
                if hasattr(self.agent_b, 'performance_tracker'):
                    accuracy = self.agent_b.performance_tracker.get_accuracy()
                    results['completeness_scores'].append(accuracy)
                
            except Exception as e:
                logger.warning(f"éªŒè¯é”™è¯¯: {e}")
                continue
        
        # è®¡ç®—æŒ‡æ ‡
        extraction_accuracy = (
            results['extraction_correct'] / results['extraction_count']
            if results['extraction_count'] > 0 else 0.0
        )
        
        validation_accuracy = (
            results['validation_correct'] / results['validation_count']
            if results['validation_count'] > 0 else 0.0
        )
        
        overall_accuracy = (extraction_accuracy + validation_accuracy) / 2
        
        completeness = (
            sum(results['completeness_scores']) / len(results['completeness_scores'])
            if results['completeness_scores'] else 0.0
        )
        
        return EvolutionMetrics(
            version=self.current_version,
            timestamp=time.time(),
            accuracy=overall_accuracy,
            extraction_accuracy=extraction_accuracy,
            validation_accuracy=validation_accuracy,
            argument_integrity=0.85,  # å ä½å€¼
            semantic_completeness=completeness,
            avg_revision_rounds=1.5
        )
    
    def _is_reasonable_triplet(self, triplet: Dict, sentence: str) -> bool:
        """
        æ£€æŸ¥ä¸‰å…ƒç»„æ˜¯å¦åˆç†
        
        ç®€å•å¯å‘å¼æ£€æŸ¥
        """
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        if not triplet.get('predicate'):
            return False
        
        # æ£€æŸ¥è°“è¯æ˜¯å¦åœ¨å¥å­ä¸­
        if triplet['predicate'] not in sentence:
            return False
        
        # æ£€æŸ¥Subject/Objectæ˜¯å¦åœ¨å¥å­ä¸­ (å¦‚æœå­˜åœ¨)
        subject = triplet.get('subject')
        if subject and subject not in sentence:
            return False
        
        return True
    
    def _check_convergence(self, current_metrics: EvolutionMetrics) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦å·²æ”¶æ•›
        
        Args:
            current_metrics: å½“å‰æŒ‡æ ‡
            
        Returns:
            æ˜¯å¦æ”¶æ•›
        """
        if len(self.evolution_history) < 2:
            return False
        
        previous_metrics = self.evolution_history[-2]
        improvement = current_metrics.accuracy - previous_metrics.accuracy
        
        # å¦‚æœæ”¹è¿›å°äºé˜ˆå€¼ï¼Œè®¤ä¸ºå·²æ”¶æ•›
        if improvement < self.convergence_threshold:
            logger.info(f"æ”¶æ•›æ£€æŸ¥: æ”¹è¿› {improvement:.4f} < é˜ˆå€¼ {self.convergence_threshold}")
            return True
        
        return False
    
    def _optimize_agents(self, metrics: EvolutionMetrics, dataset) -> None:
        """
        æ ¹æ®æŒ‡æ ‡ä¼˜åŒ–agents
        
        Args:
            metrics: å½“å‰æŒ‡æ ‡
            dataset: æ•°æ®é›†
        """
        # ä¼˜åŒ–ç­–ç•¥1: å¦‚æœæŠ½å–å‡†ç¡®ç‡ä½ï¼Œæ”¹è¿›Agent A
        if metrics.extraction_accuracy < 0.70:
            logger.info("â†’ æŠ½å–å‡†ç¡®ç‡ä½ï¼Œä¼˜åŒ–Agent A...")
            self._optimize_agent_a(metrics, dataset)
        
        # ä¼˜åŒ–ç­–ç•¥2: å¦‚æœéªŒè¯å‡†ç¡®ç‡ä½ï¼Œæ”¹è¿›Agent B
        if metrics.validation_accuracy < 0.70:
            logger.info("â†’ éªŒè¯å‡†ç¡®ç‡ä½ï¼Œä¼˜åŒ–Agent B...")
            self._optimize_agent_b(metrics, dataset)
        
        # ä¼˜åŒ–ç­–ç•¥3: å¦‚æœè¯­ä¹‰å®Œæ•´æ€§ä½ï¼Œæ”¹è¿›è§„åˆ™åº“
        if metrics.semantic_completeness < 0.75:
            logger.info("â†’ è¯­ä¹‰å®Œæ•´æ€§ä½ï¼Œæ”¹è¿›è§„åˆ™åº“...")
            self._improve_semantic_rules()
        
        logger.info("âœ“ ä¼˜åŒ–å®Œæˆ")
    
    def _optimize_agent_a(self, metrics: EvolutionMetrics, dataset) -> None:
        """ä¼˜åŒ–Agent A - ä¸‰å…ƒç»„æŠ½å–"""
        
        # ä¼˜åŒ–ç­–ç•¥:
        # 1. å¢å¼ºæç¤ºè¯ (few-shot examples)
        # 2. è°ƒæ•´æ¸©åº¦å‚æ•°
        # 3. æ”¹è¿›åå¤„ç†è§„åˆ™
        
        logger.info("  - å¢å¼ºæç¤ºè¯ä¸­çš„few-shot examples...")
        # ä»æ€§èƒ½å¥½çš„éªŒè¯ç»“æœä¸­æ·»åŠ ä¾‹å­
        
        logger.info("  - è°ƒæ•´æ¨¡å‹å‚æ•°...")
        # é™ä½temperatureä»¥æé«˜ä¸€è‡´æ€§
        
        logger.info("  - æ”¹è¿›è§£æé€»è¾‘...")
        # å¢å¼ºæ­£åˆ™è¡¨è¾¾å¼åŒ¹é…
    
    def _optimize_agent_b(self, metrics: EvolutionMetrics, dataset) -> None:
        """ä¼˜åŒ–Agent B - ä¸‰å…ƒç»„éªŒè¯"""
        
        # ä¼˜åŒ–ç­–ç•¥:
        # 1. æ‰©å±•éªŒè¯è§„åˆ™åº“
        # 2. è°ƒæ•´æƒé‡
        # 3. æ”¹è¿›åé¦ˆ
        
        logger.info("  - æ‰©å±•éªŒè¯è§„åˆ™åº“...")
        if hasattr(self.agent_b, 'rule_library'):
            # æ ¹æ®å¸¸è§é”™è¯¯æ·»åŠ æ–°è§„åˆ™
            pass
        
        logger.info("  - è°ƒæ•´é”™è¯¯ä¼˜å…ˆçº§æƒé‡...")
        # æ ¹æ®é”™è¯¯åˆ†å¸ƒè°ƒæ•´
        
        logger.info("  - æ”¹è¿›åé¦ˆæ–‡æœ¬...")
        # æ›´æ–°åé¦ˆæ¨¡æ¿
    
    def _improve_semantic_rules(self) -> None:
        """æ”¹è¿›è¯­ä¹‰è§„åˆ™åº“"""
        logger.info("  - æ›´æ–°è¯­ä¹‰è§’è‰²å®šä¹‰...")
        logger.info("  - ä¼˜åŒ–å…³é”®è¯åŒ¹é…è§„åˆ™...")
        logger.info("  - å¼ºåŒ–è®ºå…ƒå®Œæ•´æ€§æ£€æŸ¥...")
    
    def _log_metrics(self, metrics: EvolutionMetrics) -> None:
        """è®°å½•æŒ‡æ ‡"""
        logger.info(f"\nğŸ“Š ç‰ˆæœ¬ {metrics.version} çš„æ€§èƒ½æŒ‡æ ‡:")
        logger.info(f"  â€¢ æ•´ä½“å‡†ç¡®ç‡:     {metrics.accuracy:.2%}")
        logger.info(f"  â€¢ æŠ½å–å‡†ç¡®ç‡:     {metrics.extraction_accuracy:.2%}")
        logger.info(f"  â€¢ éªŒè¯å‡†ç¡®ç‡:     {metrics.validation_accuracy:.2%}")
        logger.info(f"  â€¢ è®ºå…ƒå®Œæ•´æ€§:     {metrics.argument_integrity:.2%}")
        logger.info(f"  â€¢ è¯­ä¹‰å®Œæ•´æ€§:     {metrics.semantic_completeness:.2%}")
        logger.info(f"  â€¢ å¹³å‡ä¿®è®¢è½®æ•°:   {metrics.avg_revision_rounds:.2f}")
        
        if len(self.evolution_history) > 1:
            previous = self.evolution_history[-2]
            improvement = metrics.improvement_over_previous(previous)
            logger.info(f"  â€¢ ä¸ä¸Šç‰ˆæœ¬çš„æ”¹è¿›: {improvement:+.2%}")
    
    def _generate_evolution_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆæ¼”åŒ–æŠ¥å‘Š"""
        
        if not self.evolution_history:
            return {'status': 'no_evolution'}
        
        initial = self.evolution_history[0]
        final = self.evolution_history[-1]
        
        report = {
            'total_versions': len(self.evolution_history),
            'iterations': self.current_version,
            'converged': final.accuracy >= self.target_accuracy,
            'target_accuracy': self.target_accuracy,
            'initial_metrics': asdict(initial),
            'final_metrics': asdict(final),
            'total_improvement': final.accuracy - initial.accuracy,
            'metrics_history': [asdict(m) for m in self.evolution_history],
            'evolution_timeline': self._generate_timeline()
        }
        
        return report
    
    def _generate_timeline(self) -> List[Dict]:
        """ç”Ÿæˆæ—¶é—´çº¿"""
        timeline = []
        for i, metrics in enumerate(self.evolution_history):
            timeline.append({
                'version': metrics.version,
                'accuracy': metrics.accuracy,
                'timestamp': datetime.fromtimestamp(metrics.timestamp).isoformat()
            })
        return timeline
    
    def save_evolution_history(self, filepath: str) -> None:
        """ä¿å­˜æ¼”åŒ–å†å²"""
        history = [asdict(m) for m in self.evolution_history]
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=2, default=str)
        logger.info(f"âœ“ æ¼”åŒ–å†å²å·²ä¿å­˜åˆ°: {filepath}")
    
    def get_best_version(self) -> Tuple[int, EvolutionMetrics]:
        """è·å–æ€§èƒ½æœ€å¥½çš„ç‰ˆæœ¬"""
        if not self.evolution_history:
            return None, None
        
        best = max(self.evolution_history, key=lambda m: m.accuracy)
        return best.version, best


class AdaptiveOptimizer:
    """
    è‡ªé€‚åº”ä¼˜åŒ–å™¨ - æ ¹æ®æ¼”åŒ–è¿›åº¦åŠ¨æ€è°ƒæ•´ä¼˜åŒ–ç­–ç•¥
    
    ç‰¹ç‚¹:
    - åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡
    - è‡ªé€‚åº”æ•°æ®é‡‡æ ·
    - æ™ºèƒ½è§„åˆ™æ›´æ–°
    """
    
    def __init__(self):
        """åˆå§‹åŒ–ä¼˜åŒ–å™¨"""
        self.learning_rate = 0.01
        self.learning_rate_schedule = 'exponential'
        self.data_sampling_ratio = 0.5
        self.rule_update_frequency = 3
    
    def update_learning_rate(self, iteration: int, improvement: float) -> float:
        """
        åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡
        
        Args:
            iteration: å½“å‰è¿­ä»£æ¬¡æ•°
            improvement: ä¸Šä¸€æ¬¡çš„æ”¹è¿›é‡
            
        Returns:
            æ–°çš„å­¦ä¹ ç‡
        """
        if improvement < 0.01:
            # æ”¹è¿›ç¼“æ…¢ï¼Œé™ä½å­¦ä¹ ç‡
            self.learning_rate *= 0.9
        elif improvement > 0.05:
            # æ”¹è¿›å¿«é€Ÿï¼Œç•¥å¾®æé«˜å­¦ä¹ ç‡
            self.learning_rate *= 1.05
        
        return self.learning_rate
    
    def update_sampling_ratio(self, accuracy: float) -> float:
        """
        è°ƒæ•´æ•°æ®é‡‡æ ·æ¯”ä¾‹
        
        å‡†ç¡®ç‡ä½æ—¶ä½¿ç”¨æ›´å¤šæ•°æ®
        """
        if accuracy < 0.70:
            self.data_sampling_ratio = 1.0  # ä½¿ç”¨å…¨éƒ¨æ•°æ®
        elif accuracy < 0.85:
            self.data_sampling_ratio = 0.7
        else:
            self.data_sampling_ratio = 0.5
        
        return self.data_sampling_ratio
    
    def should_update_rules(self, iteration: int) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ›´æ–°è§„åˆ™"""
        return iteration % self.rule_update_frequency == 0
